{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ML libraries  \n",
    "import torch\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Single-cell libraries\n",
    "import anndata as ad\n",
    "import scanpy as sc\n",
    "\n",
    "# Modlyn and LaminDB\n",
    "import modlyn as mn\n",
    "import lamindb as ln\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Setup\n",
    "sns.set_theme()\n",
    "%config InlineBackend.figure_formats = ['svg']\n",
    "\n",
    "# Lamin tracking (keeping from original notebook)\n",
    "project = ln.Project(name=\"ArrayLoader-Validation\")\n",
    "project.save()\n",
    "ln.track(project=\"ArrayLoader-Validation\")\n",
    "run = ln.track()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from LaminDB \n",
    "print(\"Loading dataset from arrayloader-benchmarks...\")\n",
    "artifact = ln.Artifact.using(\"laminlabs/arrayloader-benchmarks\").get(\"RymV9PfXDGDbM9ek0000\")\n",
    "adata = artifact.load()\n",
    "\n",
    "print(f\"Loaded: {adata}\")\n",
    "print(f\"Cell lines: {adata.obs['cell_line'].value_counts()}\")\n",
    "\n",
    "# Basic preprocessing\n",
    "print(\"\\nPreprocessing...\")\n",
    "# Filter cell lines with sufficient cells\n",
    "min_cells = 10\n",
    "keep_lines = adata.obs[\"cell_line\"].value_counts()\n",
    "keep_lines = keep_lines[keep_lines >= min_cells].index\n",
    "adata = adata[adata.obs[\"cell_line\"].isin(keep_lines)].copy()\n",
    "\n",
    "# Apply log transformation\n",
    "sc.pp.log1p(adata)\n",
    "print(f\"Final shape: {adata.shape}\")\n",
    "print(f\"Cell lines: {adata.obs['cell_line'].nunique()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modlyn_model = mn.models.SimpleLogReg(\n",
    "    adata=adata,\n",
    "    label_column=\"cell_line\",    \n",
    "    learning_rate=1e-2,  \n",
    "    weight_decay=0.3,\n",
    ")\n",
    "\n",
    "# Simple training with the high-level API\n",
    "print(\"Training model...\")\n",
    "modlyn_model.fit(\n",
    "    adata_train=adata[:int(0.8 * adata.n_obs)],\n",
    "    adata_val=adata[int(0.8 * adata.n_obs):],\n",
    "    train_dataloader_kwargs={\n",
    "        \"batch_size\": 512,\n",
    "        \"num_workers\": 0\n",
    "    },\n",
    "    max_epochs=100,\n",
    ")\n",
    "print(\"Training complete!\")\n",
    "\n",
    "df_modlyn = modlyn_model.get_weights()\n",
    "print(f\"Modlyn results shape: {df_modlyn.shape}\")\n",
    "print(f\"Classes: {df_modlyn.index.tolist()}\")\n",
    "df_modlyn.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize training progress using high-level API\n",
    "print(\"Creating training history visualization...\")\n",
    "\n",
    "# Show training losses using the high-level API\n",
    "modlyn_model.plot_losses()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2: Sklearn LogisticRegression (for comparison)\n",
    "X = adata.X.toarray() if hasattr(adata.X, 'toarray') else adata.X\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(adata.obs[\"cell_line\"])\n",
    "\n",
    "n_train = int(0.8 * adata.n_obs)\n",
    "X_train, X_val = X[:n_train], X[n_train:]\n",
    "y_train, y_val = y[:n_train], y[n_train:]\n",
    "\n",
    "print(f\"Training data: {X_train.shape}\")\n",
    "\n",
    "sklearn_model = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    multi_class='ovr',  # One-vs-rest like modlyn\n",
    "    solver='lbfgs',\n",
    "    random_state=42\n",
    ")\n",
    "sklearn_model.fit(X_train, y_train)\n",
    "\n",
    "df_sklearn = pd.DataFrame(\n",
    "    sklearn_model.coef_,\n",
    "    columns=adata.var_names,\n",
    "    index=le.classes_,\n",
    ")\n",
    "df_sklearn.attrs[\"method_name\"] = \"sklearn_logreg\"\n",
    "\n",
    "print(f\"Sklearn results shape: {df_sklearn.shape}\")\n",
    "print(f\"Classes: {df_sklearn.index.tolist()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = mn.eval.CompareScores(\n",
    "    dataframes=[df_modlyn, df_sklearn],\n",
    "    n_top_values=[50, 100, 200]\n",
    ")\n",
    "\n",
    "# Generate Alex's weight correlation plot\n",
    "print(\"Creating weight correlation visualization...\")\n",
    "fig, corr_df = evaluator.plot_weight_correlation(figsize=(12, 6))\n",
    "\n",
    "print(\"\\nDetailed correlation results:\")\n",
    "print(corr_df.head(10))\n",
    "\n",
    "mean_correlation = corr_df['correlation'].mean()\n",
    "print(f\"\\nFinal validation: {mean_correlation:.1%} correlation achieved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_line_categories = df_modlyn.index\n",
    "correlations = []\n",
    "comparison_data = []\n",
    "\n",
    "for cell_line in cell_line_categories:\n",
    "    if cell_line in df_sklearn.index:\n",
    "        modlyn_weights = df_modlyn.loc[cell_line].values\n",
    "        sklearn_weights = df_sklearn.loc[cell_line].values\n",
    "        \n",
    "        # Calculate correlation\n",
    "        correlation = np.corrcoef(modlyn_weights, sklearn_weights)[0, 1]\n",
    "        correlations.append(correlation)\n",
    "        \n",
    "        comparison_data.append({\n",
    "            \"cell_line\": cell_line,\n",
    "            \"correlation\": correlation,\n",
    "            \"modlyn_top_gene\": df_modlyn.columns[np.argmax(np.abs(df_modlyn.loc[cell_line]))],\n",
    "            \"sklearn_top_gene\": df_sklearn.columns[np.argmax(np.abs(df_sklearn.loc[cell_line]))],\n",
    "            \"modlyn_top_weight\": np.max(np.abs(df_modlyn.loc[cell_line])),\n",
    "            \"sklearn_top_weight\": np.max(np.abs(df_sklearn.loc[cell_line]))\n",
    "        })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(f\"\\nWeight correlations between methods:\")\n",
    "print(comparison_df[['cell_line', 'correlation', 'modlyn_top_gene', 'sklearn_top_gene']])\n",
    "\n",
    "print(f\"\\nMean correlation: {np.mean(correlations):.4f}\")\n",
    "print(f\"Min correlation: {np.min(correlations):.4f}\")\n",
    "print(f\"Max correlation: {np.max(correlations):.4f}\")\n",
    "\n",
    "identical_threshold = 0.99\n",
    "identical_count = sum(1 for corr in correlations if corr > identical_threshold)\n",
    "print(f\"\\nResults with correlation > {identical_threshold}: {identical_count}/{len(correlations)}\")\n",
    "\n",
    "if identical_count == len(correlations):\n",
    "    print(\"SUCCESS: All results are essentially identical!\")\n",
    "elif np.mean(correlations) > 0.95:\n",
    "    print(\"Results are highly similar but not identical - may need hyperparameter tuning\")\n",
    "else:\n",
    "    print(\"Results differ significantly - investigation needed\")\n",
    "\n",
    "# Visualize the comparison (your exact code)\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "axes[0, 0].hist(correlations, bins=20, alpha=0.7, edgecolor='black')\n",
    "axes[0, 0].axvline(np.mean(correlations), color='red', linestyle='--', \n",
    "                   label=f'Mean: {np.mean(correlations):.3f}')\n",
    "axes[0, 0].set_xlabel('Weight Correlation')\n",
    "axes[0, 0].set_ylabel('Count')\n",
    "axes[0, 0].set_title('Modlyn vs Sklearn Weight Correlations')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "first_cell_line = cell_line_categories[0]\n",
    "if first_cell_line in df_sklearn.index:\n",
    "    modlyn_w = df_modlyn.loc[first_cell_line].values\n",
    "    sklearn_w = df_sklearn.loc[first_cell_line].values\n",
    "    \n",
    "    axes[0, 1].scatter(modlyn_w, sklearn_w, alpha=0.6, s=10)\n",
    "    axes[0, 1].plot([modlyn_w.min(), modlyn_w.max()], \n",
    "                    [sklearn_w.min(), sklearn_w.max()], 'r--', alpha=0.8)\n",
    "    axes[0, 1].set_xlabel('Modlyn Weights')\n",
    "    axes[0, 1].set_ylabel('Sklearn Weights')\n",
    "    axes[0, 1].set_title(f'Weight Comparison: {first_cell_line}')\n",
    "\n",
    "top_n = 10\n",
    "if first_cell_line in df_sklearn.index:\n",
    "    modlyn_top_genes = df_modlyn.loc[first_cell_line].abs().nlargest(top_n).index.tolist()\n",
    "    sklearn_top_genes = df_sklearn.loc[first_cell_line].abs().nlargest(top_n).index.tolist()\n",
    "    \n",
    "    overlap = len(set(modlyn_top_genes) & set(sklearn_top_genes))\n",
    "    axes[1, 0].bar(['Modlyn Only', 'Overlap', 'Sklearn Only'], \n",
    "                   [top_n - overlap, overlap, top_n - overlap])\n",
    "    axes[1, 0].set_title(f'Top {top_n} Gene Overlap: {first_cell_line}')\n",
    "    axes[1, 0].set_ylabel('Gene Count')\n",
    "\n",
    "y_train_pred_sklearn = sklearn_model.predict(X_train)\n",
    "acc_sklearn = (y_train_pred_sklearn == y_train).mean()\n",
    "\n",
    "with torch.no_grad():\n",
    "    modlyn_pred = modlyn_model(torch.tensor(X_train, dtype=torch.float32))\n",
    "    y_train_pred_modlyn = modlyn_pred.argmax(dim=1).numpy()\n",
    "    acc_modlyn = (y_train_pred_modlyn == y_train).mean()\n",
    "\n",
    "methods = ['Modlyn', 'Sklearn']\n",
    "axes[1, 1].bar(methods, [acc_modlyn, acc_sklearn])\n",
    "axes[1, 1].set_title('Training Accuracy Comparison')\n",
    "axes[1, 1].set_ylabel('Accuracy')\n",
    "axes[1, 1].set_ylim(0, 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nTraining Accuracies:\")\n",
    "print(f\"Modlyn: {acc_modlyn:.4f}\")\n",
    "print(f\"Sklearn: {acc_sklearn:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compare with Scanpy methods\n",
    "# Scanpy logistic regression\n",
    "sc.tl.rank_genes_groups(adata, 'cell_line', method='logreg', key_added='sc_logreg')\n",
    "df_scanpy_logreg = sc.get.rank_genes_groups_df(adata, group=None, key=\"sc_logreg\").pivot(\n",
    "    index='group', columns='names', values='scores'\n",
    ")\n",
    "df_scanpy_logreg.attrs[\"method_name\"] = \"scanpy_logreg\"\n",
    "\n",
    "# Scanpy Wilcoxon\n",
    "sc.tl.rank_genes_groups(adata, 'cell_line', method='wilcoxon', key_added='sc_wilcoxon') \n",
    "df_scanpy_wilcoxon = sc.get.rank_genes_groups_df(adata, group=None, key=\"sc_wilcoxon\").pivot(\n",
    "    index='group', columns='names', values='scores'\n",
    ")\n",
    "df_scanpy_wilcoxon.attrs[\"method_name\"] = \"scanpy_wilcoxon\"\n",
    "\n",
    "print(\"Scanpy methods complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use modlyn.eval for comprehensive comparison\n",
    "compare = mn.eval.CompareScores([df_modlyn, df_scanpy_logreg, df_scanpy_wilcoxon])\n",
    "compare.compute_jaccard_comparison()\n",
    "compare.plot_jaccard_comparison()\n",
    "\n",
    "compare.plot_heatmaps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lamin_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
