{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ML libraries  \n",
    "import torch\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Single-cell libraries\n",
    "import anndata as ad\n",
    "import scanpy as sc\n",
    "\n",
    "# Modlyn and LaminDB\n",
    "import modlyn as mn\n",
    "import lamindb as ln\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Setup\n",
    "sns.set_theme()\n",
    "%config InlineBackend.figure_formats = ['svg']\n",
    "\n",
    "# Lamin tracking (keeping from original notebook)\n",
    "project = ln.Project(name=\"ArrayLoader-Validation\")\n",
    "project.save()\n",
    "ln.track(project=\"ArrayLoader-Validation\")\n",
    "run = ln.track()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from LaminDB \n",
    "print(\"Loading dataset from arrayloader-benchmarks...\")\n",
    "artifact = ln.Artifact.using(\"laminlabs/arrayloader-benchmarks\").get(\"RymV9PfXDGDbM9ek0000\")\n",
    "adata = artifact.load()\n",
    "\n",
    "print(f\"Loaded: {adata}\")\n",
    "print(f\"Cell lines: {adata.obs['cell_line'].value_counts()}\")\n",
    "\n",
    "# Basic preprocessing\n",
    "print(\"\\nPreprocessing...\")\n",
    "# Filter cell lines with sufficient cells\n",
    "min_cells = 10\n",
    "keep_lines = adata.obs[\"cell_line\"].value_counts()\n",
    "keep_lines = keep_lines[keep_lines >= min_cells].index\n",
    "adata = adata[adata.obs[\"cell_line\"].isin(keep_lines)].copy()\n",
    "\n",
    "# Apply log transformation\n",
    "sc.pp.log1p(adata)\n",
    "print(f\"Final shape: {adata.shape}\")\n",
    "print(f\"Cell lines: {adata.obs['cell_line'].nunique()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modlyn_model = mn.models.SimpleLogReg(\n",
    "    adata=adata,\n",
    "    label_column=\"cell_line\",    \n",
    "    learning_rate=1e-2,  \n",
    "    weight_decay=0.3,\n",
    ")\n",
    "\n",
    "# Simple training with the high-level API\n",
    "print(\"Training model...\")\n",
    "modlyn_model.fit(\n",
    "    adata_train=adata[:int(0.8 * adata.n_obs)],\n",
    "    adata_val=adata[int(0.8 * adata.n_obs):],\n",
    "    train_dataloader_kwargs={\n",
    "        \"batch_size\": 512,\n",
    "        \"num_workers\": 0\n",
    "    },\n",
    "    max_epochs=100,\n",
    ")\n",
    "print(\"Training complete!\")\n",
    "\n",
    "df_modlyn = modlyn_model.get_weights()\n",
    "print(f\"Modlyn results shape: {df_modlyn.shape}\")\n",
    "print(f\"Classes: {df_modlyn.index.tolist()}\")\n",
    "df_modlyn.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize training progress using high-level API\n",
    "print(\"Creating training history visualization...\")\n",
    "\n",
    "# Show training losses using the high-level API\n",
    "modlyn_model.plot_losses()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2: Sklearn LogisticRegression (for comparison)\n",
    "X = adata.X.toarray() if hasattr(adata.X, 'toarray') else adata.X\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(adata.obs[\"cell_line\"])\n",
    "\n",
    "n_train = int(0.8 * adata.n_obs)\n",
    "X_train, X_val = X[:n_train], X[n_train:]\n",
    "y_train, y_val = y[:n_train], y[n_train:]\n",
    "\n",
    "print(f\"Training data: {X_train.shape}\")\n",
    "\n",
    "sklearn_model = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    multi_class='ovr',  # One-vs-rest like modlyn\n",
    "    solver='lbfgs',\n",
    "    random_state=42\n",
    ")\n",
    "sklearn_model.fit(X_train, y_train)\n",
    "\n",
    "df_sklearn = pd.DataFrame(\n",
    "    sklearn_model.coef_,\n",
    "    columns=adata.var_names,\n",
    "    index=le.classes_,\n",
    ")\n",
    "df_sklearn.attrs[\"method_name\"] = \"sklearn_logreg\"\n",
    "\n",
    "print(f\"Sklearn results shape: {df_sklearn.shape}\")\n",
    "print(f\"Classes: {df_sklearn.index.tolist()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = mn.eval.CompareScores(\n",
    "    dataframes=[df_modlyn, df_sklearn],\n",
    "    n_top_values=[50, 100, 200]\n",
    ")\n",
    "\n",
    "# Generate Alex's weight correlation plot\n",
    "print(\"Creating weight correlation visualization...\")\n",
    "fig, corr_df = evaluator.plot_weight_correlation(figsize=(12, 6))\n",
    "\n",
    "print(\"\\nDetailed correlation results:\")\n",
    "print(corr_df.head(10))\n",
    "\n",
    "mean_correlation = corr_df['correlation'].mean()\n",
    "print(f\"\\nFinal validation: {mean_correlation:.1%} correlation achieved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_line_categories = df_modlyn.index\n",
    "correlations = []\n",
    "comparison_data = []\n",
    "\n",
    "for cell_line in cell_line_categories:\n",
    "    if cell_line in df_sklearn.index:\n",
    "        modlyn_weights = df_modlyn.loc[cell_line].values\n",
    "        sklearn_weights = df_sklearn.loc[cell_line].values\n",
    "        \n",
    "        # Calculate correlation\n",
    "        correlation = np.corrcoef(modlyn_weights, sklearn_weights)[0, 1]\n",
    "        correlations.append(correlation)\n",
    "        \n",
    "        comparison_data.append({\n",
    "            \"cell_line\": cell_line,\n",
    "            \"correlation\": correlation,\n",
    "            \"modlyn_top_gene\": df_modlyn.columns[np.argmax(np.abs(df_modlyn.loc[cell_line]))],\n",
    "            \"sklearn_top_gene\": df_sklearn.columns[np.argmax(np.abs(df_sklearn.loc[cell_line]))],\n",
    "            \"modlyn_top_weight\": np.max(np.abs(df_modlyn.loc[cell_line])),\n",
    "            \"sklearn_top_weight\": np.max(np.abs(df_sklearn.loc[cell_line]))\n",
    "        })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(f\"\\nWeight correlations between methods:\")\n",
    "print(comparison_df[['cell_line', 'correlation', 'modlyn_top_gene', 'sklearn_top_gene']])\n",
    "\n",
    "print(f\"\\nMean correlation: {np.mean(correlations):.4f}\")\n",
    "print(f\"Min correlation: {np.min(correlations):.4f}\")\n",
    "print(f\"Max correlation: {np.max(correlations):.4f}\")\n",
    "\n",
    "identical_threshold = 0.99\n",
    "identical_count = sum(1 for corr in correlations if corr > identical_threshold)\n",
    "print(f\"\\nResults with correlation > {identical_threshold}: {identical_count}/{len(correlations)}\")\n",
    "\n",
    "if identical_count == len(correlations):\n",
    "    print(\"SUCCESS: All results are essentially identical!\")\n",
    "elif np.mean(correlations) > 0.95:\n",
    "    print(\"Results are highly similar but not identical - may need hyperparameter tuning\")\n",
    "else:\n",
    "    print(\"Results differ significantly - investigation needed\")\n",
    "\n",
    "# Visualize the comparison (your exact code)\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "axes[0, 0].hist(correlations, bins=20, alpha=0.7, edgecolor='black')\n",
    "axes[0, 0].axvline(np.mean(correlations), color='red', linestyle='--', \n",
    "                   label=f'Mean: {np.mean(correlations):.3f}')\n",
    "axes[0, 0].set_xlabel('Weight Correlation')\n",
    "axes[0, 0].set_ylabel('Count')\n",
    "axes[0, 0].set_title('Modlyn vs Sklearn Weight Correlations')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "first_cell_line = cell_line_categories[0]\n",
    "if first_cell_line in df_sklearn.index:\n",
    "    modlyn_w = df_modlyn.loc[first_cell_line].values\n",
    "    sklearn_w = df_sklearn.loc[first_cell_line].values\n",
    "    \n",
    "    axes[0, 1].scatter(modlyn_w, sklearn_w, alpha=0.6, s=10)\n",
    "    axes[0, 1].plot([modlyn_w.min(), modlyn_w.max()], \n",
    "                    [sklearn_w.min(), sklearn_w.max()], 'r--', alpha=0.8)\n",
    "    axes[0, 1].set_xlabel('Modlyn Weights')\n",
    "    axes[0, 1].set_ylabel('Sklearn Weights')\n",
    "    axes[0, 1].set_title(f'Weight Comparison: {first_cell_line}')\n",
    "\n",
    "top_n = 10\n",
    "if first_cell_line in df_sklearn.index:\n",
    "    modlyn_top_genes = df_modlyn.loc[first_cell_line].abs().nlargest(top_n).index.tolist()\n",
    "    sklearn_top_genes = df_sklearn.loc[first_cell_line].abs().nlargest(top_n).index.tolist()\n",
    "    \n",
    "    overlap = len(set(modlyn_top_genes) & set(sklearn_top_genes))\n",
    "    axes[1, 0].bar(['Modlyn Only', 'Overlap', 'Sklearn Only'], \n",
    "                   [top_n - overlap, overlap, top_n - overlap])\n",
    "    axes[1, 0].set_title(f'Top {top_n} Gene Overlap: {first_cell_line}')\n",
    "    axes[1, 0].set_ylabel('Gene Count')\n",
    "\n",
    "y_train_pred_sklearn = sklearn_model.predict(X_train)\n",
    "acc_sklearn = (y_train_pred_sklearn == y_train).mean()\n",
    "\n",
    "with torch.no_grad():\n",
    "    modlyn_pred = modlyn_model(torch.tensor(X_train, dtype=torch.float32))\n",
    "    y_train_pred_modlyn = modlyn_pred.argmax(dim=1).numpy()\n",
    "    acc_modlyn = (y_train_pred_modlyn == y_train).mean()\n",
    "\n",
    "methods = ['Modlyn', 'Sklearn']\n",
    "axes[1, 1].bar(methods, [acc_modlyn, acc_sklearn])\n",
    "axes[1, 1].set_title('Training Accuracy Comparison')\n",
    "axes[1, 1].set_ylabel('Accuracy')\n",
    "axes[1, 1].set_ylim(0, 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nTraining Accuracies:\")\n",
    "print(f\"Modlyn: {acc_modlyn:.4f}\")\n",
    "print(f\"Sklearn: {acc_sklearn:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arrayloaders.io import read_lazy, ClassificationDataModule\n",
    "print(\"ArrayLoaders package detected\")\n",
    "\n",
    "# Access the same dataset used for H5AD validation\n",
    "artifact_zarr = ln.Artifact.using(\"laminlabs/arrayloader-benchmarks\").get(\"RymV9PfXDGDbM9ek0000\")\n",
    "zarr_path = artifact_zarr.cache()\n",
    "print(f\"Dataset path: {zarr_path}\")\n",
    "\n",
    "# Verify zarr store compatibility\n",
    "import os\n",
    "if os.path.exists(zarr_path) and (str(zarr_path).endswith('.zarr') or os.path.isdir(zarr_path)):\n",
    "    print(\"Zarr format detected\")\n",
    "    \n",
    "    # Attempt arrayloader data access\n",
    "    try:\n",
    "        adata_arrayloader = read_lazy(zarr_path)\n",
    "        print(f\"ArrayLoader successful: {adata_arrayloader.shape}\")\n",
    "        arrayloader_available = True\n",
    "    except Exception as e:\n",
    "        print(f\"ArrayLoader failed: {e}\")\n",
    "        arrayloader_available = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ArrayLoader equivalence validation\n",
    "if arrayloader_available:\n",
    "    print(\"Training Modlyn with ArrayLoader data...\")\n",
    "    \n",
    "    # Convert to memory-resident AnnData for preprocessing\n",
    "    adata_al = adata_arrayloader.to_memory() if hasattr(adata_arrayloader, 'to_memory') else adata_arrayloader\n",
    "    \n",
    "    # Apply identical preprocessing pipeline\n",
    "    min_cells = 10\n",
    "    keep_lines = adata_al.obs[\"cell_line\"].value_counts()\n",
    "    keep_lines = keep_lines[keep_lines >= min_cells].index\n",
    "    adata_al = adata_al[adata_al.obs[\"cell_line\"].isin(keep_lines)].copy()\n",
    "    sc.pp.log1p(adata_al)\n",
    "    \n",
    "    print(f\"ArrayLoader data processed: {adata_al.shape}\")\n",
    "    \n",
    "    # Train with identical hyperparameters\n",
    "    modlyn_model_al = mn.models.SimpleLogReg(\n",
    "        adata=adata_al,\n",
    "        label_column=\"cell_line\",    \n",
    "        learning_rate=1e-2,  \n",
    "        weight_decay=0.3,\n",
    "    )\n",
    "    \n",
    "    modlyn_model_al.fit(\n",
    "        adata_train=adata_al[:int(0.8 * adata_al.n_obs)],\n",
    "        adata_val=adata_al[int(0.8 * adata_al.n_obs):],\n",
    "        train_dataloader_kwargs={\"batch_size\": 512, \"num_workers\": 0},\n",
    "        max_epochs=100,\n",
    "    )\n",
    "    \n",
    "    df_modlyn_al = modlyn_model_al.get_weights()\n",
    "    \n",
    "    # Equivalence analysis\n",
    "    print(\"Analyzing ArrayLoader equivalence...\")\n",
    "    \n",
    "    # Convert sets to lists for pandas indexing\n",
    "    common_cell_lines = list(set(df_modlyn.index) & set(df_modlyn_al.index))\n",
    "    common_genes = list(set(df_modlyn.columns) & set(df_modlyn_al.columns))\n",
    "    \n",
    "    print(f\"Comparing {len(common_cell_lines)} cell lines across {len(common_genes)} genes\")\n",
    "    \n",
    "    if len(common_cell_lines) > 0 and len(common_genes) > 0:\n",
    "        correlations_al = []\n",
    "        \n",
    "        for cell_line in common_cell_lines:\n",
    "            h5ad_weights = df_modlyn.loc[cell_line, common_genes].values\n",
    "            al_weights = df_modlyn_al.loc[cell_line, common_genes].values\n",
    "            correlation = np.corrcoef(h5ad_weights, al_weights)[0, 1]\n",
    "            correlations_al.append(correlation)\n",
    "        \n",
    "        mean_correlation_al = np.mean(correlations_al)\n",
    "        \n",
    "        print(f\"ArrayLoader equivalence correlation: {mean_correlation_al:.4f}\")\n",
    "        print(f\"Range: {np.min(correlations_al):.4f} to {np.max(correlations_al):.4f}\")\n",
    "        \n",
    "        # Determine equivalence status\n",
    "        if mean_correlation_al > 0.99:\n",
    "            equivalence_status = \"IDENTICAL\"\n",
    "        elif mean_correlation_al > 0.95:\n",
    "            equivalence_status = \"HIGHLY EQUIVALENT\"\n",
    "        else:\n",
    "            equivalence_status = \"REQUIRES INVESTIGATION\"\n",
    "        \n",
    "        print(f\"Equivalence assessment: {equivalence_status}\")\n",
    "        \n",
    "        # Generate comparison visualization\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "        \n",
    "        axes[0].hist(correlations_al, bins=15, alpha=0.7, edgecolor='black')\n",
    "        axes[0].axvline(mean_correlation_al, color='red', linestyle='--', \n",
    "                       label=f'Mean: {mean_correlation_al:.3f}')\n",
    "        axes[0].set_xlabel('Correlation')\n",
    "        axes[0].set_ylabel('Frequency')\n",
    "        axes[0].set_title('H5AD vs ArrayLoader Correlations')\n",
    "        axes[0].legend()\n",
    "        \n",
    "        # Weight scatter comparison for representative cell line\n",
    "        representative_line = common_cell_lines[0]\n",
    "        h5ad_weights = df_modlyn.loc[representative_line, common_genes].values\n",
    "        al_weights = df_modlyn_al.loc[representative_line, common_genes].values\n",
    "        \n",
    "        axes[1].scatter(h5ad_weights, al_weights, alpha=0.6, s=15)\n",
    "        axes[1].plot([h5ad_weights.min(), h5ad_weights.max()], \n",
    "                    [al_weights.min(), al_weights.max()], 'r--', alpha=0.8)\n",
    "        axes[1].set_xlabel('H5AD Weights')\n",
    "        axes[1].set_ylabel('ArrayLoader Weights')\n",
    "        axes[1].set_title(f'Weight Correlation: {representative_line}')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"Validation summary:\")\n",
    "        print(f\"H5AD-Sklearn correlation: {mean_correlation:.3f}\")\n",
    "        print(f\"H5AD-ArrayLoader correlation: {mean_correlation_al:.3f}\")\n",
    "        print(f\"ArrayLoader validation: {equivalence_status}\")\n",
    "        \n",
    "    else:\n",
    "        print(\"Insufficient overlap for comparison\")\n",
    "        \n",
    "else:\n",
    "    print(\"ArrayLoader test skipped - zarr store unavailable\")\n",
    "    print(f\"H5AD validation achieved {mean_correlation:.3f} correlation with sklearn\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compare with Scanpy methods\n",
    "# Scanpy logistic regression\n",
    "sc.tl.rank_genes_groups(adata, 'cell_line', method='logreg', key_added='sc_logreg')\n",
    "df_scanpy_logreg = sc.get.rank_genes_groups_df(adata, group=None, key=\"sc_logreg\").pivot(\n",
    "    index='group', columns='names', values='scores'\n",
    ")\n",
    "df_scanpy_logreg.attrs[\"method_name\"] = \"scanpy_logreg\"\n",
    "\n",
    "# Scanpy Wilcoxon\n",
    "sc.tl.rank_genes_groups(adata, 'cell_line', method='wilcoxon', key_added='sc_wilcoxon') \n",
    "df_scanpy_wilcoxon = sc.get.rank_genes_groups_df(adata, group=None, key=\"sc_wilcoxon\").pivot(\n",
    "    index='group', columns='names', values='scores'\n",
    ")\n",
    "df_scanpy_wilcoxon.attrs[\"method_name\"] = \"scanpy_wilcoxon\"\n",
    "\n",
    "print(\"Scanpy methods complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use modlyn.eval for comprehensive comparison\n",
    "compare = mn.eval.CompareScores([df_modlyn, df_scanpy_logreg, df_scanpy_wilcoxon])\n",
    "compare.compute_jaccard_comparison()\n",
    "compare.plot_jaccard_comparison()\n",
    "\n",
    "compare.plot_heatmaps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln.finish()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lamin_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
