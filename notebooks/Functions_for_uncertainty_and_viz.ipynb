{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "772df14f-a3de-4e1f-b5d9-583af0d2282e",
   "metadata": {},
   "source": [
    "# Notebook for uncertainty estimation, volcano plots, dot plots, heatmaps, and the biological interpretation framework you outlined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9495124c-51a5-4a40-b277-c79251534ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.utils import resample\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4e4ba8-0d37-4ae5-9767-ae196d9f2dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearModelAnalyzer:\n",
    "    \"\"\"Comprehensive analysis for linear models with uncertainty estimation\"\"\"\n",
    "    \n",
    "    def __init__(self, model, adata, datamodule=None):\n",
    "        self.model = model\n",
    "        self.adata = adata\n",
    "        self.datamodule = datamodule\n",
    "        self.weights = model.linear.weight.detach().cpu().numpy()\n",
    "        self.bias = model.linear.bias.detach().cpu().numpy() if model.linear.bias is not None else None\n",
    "        \n",
    "        # Get class and gene names\n",
    "        if 'y' in adata.obs.columns:\n",
    "            if hasattr(adata.obs['y'], 'cat'):\n",
    "                self.class_names = adata.obs['y'].cat.categories.tolist()\n",
    "            else:\n",
    "                self.class_names = sorted(adata.obs['y'].unique())\n",
    "        else:\n",
    "            self.class_names = [f\"Class_{i}\" for i in range(model.linear.out_features)]\n",
    "        \n",
    "        self.gene_names = [f\"Gene_{i:05d}\" for i in range(adata.n_vars)]\n",
    "        self.n_classes, self.n_genes = self.weights.shape\n",
    "        \n",
    "    def bootstrap_uncertainty(self, n_bootstrap=100, sample_size=0.8):\n",
    "        \"\"\"\n",
    "        Estimate weight uncertainty using bootstrap sampling\n",
    "        Returns mean weights and standard errors\n",
    "        \"\"\"\n",
    "        print(f\"Computing uncertainty via bootstrap (n={n_bootstrap})...\")\n",
    "        \n",
    "        if self.datamodule is None:\n",
    "            print(\"Warning: No datamodule provided, using simple weight-based uncertainty\")\n",
    "            return self._simple_weight_uncertainty()\n",
    "        \n",
    "        bootstrap_weights = []\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Get validation data\n",
    "        val_loader = self.datamodule.val_dataloader()\n",
    "        all_x, all_y = [], []\n",
    "        \n",
    "        for batch in val_loader:\n",
    "            x, y = batch\n",
    "            all_x.append(x.cpu())\n",
    "            all_y.append(y.cpu())\n",
    "        \n",
    "        all_x = torch.cat(all_x)\n",
    "        all_y = torch.cat(all_y)\n",
    "        \n",
    "        n_samples = len(all_x)\n",
    "        bootstrap_size = int(sample_size * n_samples)\n",
    "        \n",
    "        for i in range(n_bootstrap):\n",
    "            if i % 20 == 0:\n",
    "                print(f\"  Bootstrap {i+1}/{n_bootstrap}\")\n",
    "            \n",
    "            # Bootstrap sample\n",
    "            indices = torch.randint(0, n_samples, (bootstrap_size,))\n",
    "            x_boot = all_x[indices]\n",
    "            y_boot = all_y[indices]\n",
    "            \n",
    "            # Fit simple logistic regression on bootstrap sample\n",
    "            try:\n",
    "                # Simple gradient descent for speed\n",
    "                weights_boot = self._fit_bootstrap_weights(x_boot, y_boot)\n",
    "                bootstrap_weights.append(weights_boot)\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        if len(bootstrap_weights) > 10:\n",
    "            bootstrap_weights = np.array(bootstrap_weights)\n",
    "            weight_means = np.mean(bootstrap_weights, axis=0)\n",
    "            weight_stds = np.std(bootstrap_weights, axis=0)\n",
    "            \n",
    "            print(f\"‚úÖ Bootstrap completed with {len(bootstrap_weights)} successful fits\")\n",
    "            return weight_means, weight_stds\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è  Bootstrap failed, using simple uncertainty estimation\")\n",
    "            return self._simple_weight_uncertainty()\n",
    "    \n",
    "    def _fit_bootstrap_weights(self, x, y, lr=0.01, n_steps=50):\n",
    "        \"\"\"Quick weight fitting for bootstrap\"\"\"\n",
    "        device = x.device\n",
    "        weights = torch.randn(self.n_classes, self.n_genes, device=device) * 0.01\n",
    "        weights.requires_grad_(True)\n",
    "        \n",
    "        optimizer = torch.optim.Adam([weights], lr=lr)\n",
    "        \n",
    "        for _ in range(n_steps):\n",
    "            logits = torch.mm(x, weights.t())\n",
    "            loss = F.cross_entropy(logits, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        return weights.detach().cpu().numpy()\n",
    "    \n",
    "    def _simple_weight_uncertainty(self):\n",
    "        \"\"\"Simple uncertainty based on weight magnitude and class separation\"\"\"\n",
    "        # Estimate uncertainty based on weight statistics\n",
    "        weight_stds = np.abs(self.weights) * 0.1  # Simple heuristic\n",
    "        \n",
    "        # Higher uncertainty for smaller weights\n",
    "        weight_stds += 0.05 / (np.abs(self.weights) + 0.01)\n",
    "        \n",
    "        return self.weights, weight_stds\n",
    "    \n",
    "    def create_volcano_plot(self, class1_idx=0, class2_idx=1, uncertainty=None):\n",
    "        \"\"\"\n",
    "        Create volcano plot comparing two classes\n",
    "        X-axis: log fold change (weight difference)\n",
    "        Y-axis: -log10(p-value) or significance metric\n",
    "        \"\"\"\n",
    "        class1_name = self.class_names[class1_idx]\n",
    "        class2_name = self.class_names[class2_idx]\n",
    "        \n",
    "        # Calculate log fold change (weight difference)\n",
    "        log_fc = self.weights[class1_idx] - self.weights[class2_idx]\n",
    "        \n",
    "        # Calculate p-values or significance metric\n",
    "        if uncertainty is not None:\n",
    "            _, weight_stds = uncertainty\n",
    "            # T-test like statistic\n",
    "            se_diff = np.sqrt(weight_stds[class1_idx]**2 + weight_stds[class2_idx]**2)\n",
    "            t_stats = np.abs(log_fc) / (se_diff + 1e-8)\n",
    "            p_values = 2 * (1 - norm.cdf(t_stats))  # Two-tailed test\n",
    "            neg_log_p = -np.log10(p_values + 1e-10)\n",
    "        else:\n",
    "            # Use weight magnitude as significance proxy\n",
    "            neg_log_p = np.log10(np.abs(log_fc) + 0.01)\n",
    "        \n",
    "        # Create volcano plot\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        \n",
    "        # Color points by significance and effect size\n",
    "        colors = ['gray' if (abs(fc) < 0.5 or nlp < 2) else 'red' if fc > 0 else 'blue' \n",
    "                 for fc, nlp in zip(log_fc, neg_log_p)]\n",
    "        \n",
    "        scatter = plt.scatter(log_fc, neg_log_p, c=colors, alpha=0.6, s=20)\n",
    "        \n",
    "        # Add significance thresholds\n",
    "        plt.axhline(y=2, color='black', linestyle='--', alpha=0.5, label='p=0.01')\n",
    "        plt.axvline(x=0.5, color='black', linestyle='--', alpha=0.5)\n",
    "        plt.axvline(x=-0.5, color='black', linestyle='--', alpha=0.5)\n",
    "        \n",
    "        plt.xlabel(f'Weight Difference ({class1_name} - {class2_name})')\n",
    "        plt.ylabel('-log10(p-value)' if uncertainty else 'log10(|Weight Difference|)')\n",
    "        plt.title(f'Volcano Plot: {class1_name} vs {class2_name}')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Annotate top genes\n",
    "        top_genes_idx = np.argsort(neg_log_p)[-10:]\n",
    "        for idx in top_genes_idx:\n",
    "            if abs(log_fc[idx]) > 0.3:  # Only annotate if effect size is meaningful\n",
    "                plt.annotate(self.gene_names[idx], \n",
    "                           (log_fc[idx], neg_log_p[idx]),\n",
    "                           xytext=(5, 5), textcoords='offset points',\n",
    "                           fontsize=8, alpha=0.8)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'volcano_plot_{class1_name}_vs_{class2_name}.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        return log_fc, neg_log_p\n",
    "    \n",
    "    def create_dot_plot(self, top_k=20, uncertainty=None):\n",
    "        \"\"\"\n",
    "        Create dot plot showing top genes per class with effect size and uncertainty\n",
    "        \"\"\"\n",
    "        fig, ax = plt.subplots(figsize=(15, max(8, len(self.class_names) * 0.4)))\n",
    "        \n",
    "        # Get top genes per class\n",
    "        plot_data = []\n",
    "        for class_idx, class_name in enumerate(self.class_names):\n",
    "            class_weights = self.weights[class_idx]\n",
    "            top_indices = np.argsort(np.abs(class_weights))[-top_k:][::-1]\n",
    "            \n",
    "            for rank, gene_idx in enumerate(top_indices):\n",
    "                weight = class_weights[gene_idx]\n",
    "                uncertainty_val = uncertainty[1][class_idx, gene_idx] if uncertainty else 0.1\n",
    "                \n",
    "                plot_data.append({\n",
    "                    'class': class_name,\n",
    "                    'gene': self.gene_names[gene_idx],\n",
    "                    'weight': weight,\n",
    "                    'abs_weight': abs(weight),\n",
    "                    'uncertainty': uncertainty_val,\n",
    "                    'rank': rank,\n",
    "                    'class_idx': class_idx,\n",
    "                    'gene_idx': gene_idx\n",
    "                })\n",
    "        \n",
    "        df = pd.DataFrame(plot_data)\n",
    "        \n",
    "        # Create dot plot\n",
    "        for class_idx, class_name in enumerate(self.class_names[:min(20, len(self.class_names))]):\n",
    "            class_data = df[df['class'] == class_name].head(top_k)\n",
    "            \n",
    "            y_pos = class_idx\n",
    "            x_pos = class_data['weight'].values\n",
    "            sizes = (class_data['abs_weight'].values / class_data['abs_weight'].max() * 200)\n",
    "            \n",
    "            # Color by effect direction\n",
    "            colors = ['red' if w > 0 else 'blue' for w in x_pos]\n",
    "            \n",
    "            ax.scatter(x_pos, [y_pos] * len(x_pos), s=sizes, c=colors, alpha=0.6)\n",
    "            \n",
    "            # Add uncertainty bars if available\n",
    "            if uncertainty:\n",
    "                uncertainties = class_data['uncertainty'].values\n",
    "                ax.errorbar(x_pos, [y_pos] * len(x_pos), xerr=uncertainties, \n",
    "                           fmt='none', color='black', alpha=0.3, capsize=2)\n",
    "        \n",
    "        ax.set_yticks(range(min(20, len(self.class_names))))\n",
    "        ax.set_yticklabels(self.class_names[:min(20, len(self.class_names))])\n",
    "        ax.set_xlabel('Gene Weight')\n",
    "        ax.set_title(f'Top {top_k} Genes per Class (Dot Plot)')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.axvline(x=0, color='black', linestyle='-', alpha=0.5)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('dotplot_genes_per_class.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def create_heatmap_analysis(self, top_k=30):\n",
    "        \"\"\"\n",
    "        Create comprehensive heatmap analysis\n",
    "        \"\"\"\n",
    "        # 1. Gene importance heatmap\n",
    "        gene_importance = np.mean(np.abs(self.weights), axis=0)\n",
    "        top_gene_indices = np.argsort(gene_importance)[-top_k:][::-1]\n",
    "        \n",
    "        # Select subset of classes for readability\n",
    "        n_classes_show = min(20, len(self.class_names))\n",
    "        class_subset = range(0, len(self.class_names), max(1, len(self.class_names) // n_classes_show))[:n_classes_show]\n",
    "        \n",
    "        weights_subset = self.weights[np.ix_(class_subset, top_gene_indices)]\n",
    "        \n",
    "        plt.figure(figsize=(15, 10))\n",
    "        \n",
    "        # Create heatmap\n",
    "        sns.heatmap(weights_subset, \n",
    "                   xticklabels=[self.gene_names[i] for i in top_gene_indices],\n",
    "                   yticklabels=[self.class_names[i] for i in class_subset],\n",
    "                   cmap='RdBu_r', center=0, \n",
    "                   cbar_kws={'label': 'Gene Weight'})\n",
    "        \n",
    "        plt.title(f'Heatmap: Top {top_k} Genes vs Classes')\n",
    "        plt.xlabel('Genes')\n",
    "        plt.ylabel('Classes')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.yticks(rotation=0)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('heatmap_genes_vs_classes.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        # 2. Class similarity heatmap\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        class_correlations = np.corrcoef(self.weights)\n",
    "        \n",
    "        sns.heatmap(class_correlations, \n",
    "                   xticklabels=self.class_names,\n",
    "                   yticklabels=self.class_names,\n",
    "                   cmap='coolwarm', center=0,\n",
    "                   square=True,\n",
    "                   cbar_kws={'label': 'Correlation'})\n",
    "        \n",
    "        plt.title('Class Similarity (Weight Pattern Correlation)')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.yticks(rotation=0)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('heatmap_class_similarity.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        return top_gene_indices, class_correlations\n",
    "    \n",
    "    def analyze_confounders_vs_biology(self):\n",
    "        \"\"\"\n",
    "        Analyze confounders (plate effects) vs biological variables\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"CONFOUNDER vs BIOLOGICAL ANALYSIS\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Identify potential confounders and biological variables\n",
    "        obs_columns = self.adata.obs.columns.tolist()\n",
    "        \n",
    "        # Confounders (technical variables)\n",
    "        confounders = [col for col in obs_columns if any(x in col.lower() for x in \n",
    "                      ['plate', 'batch', 'barcode', 'sublibrary', 'sample'])]\n",
    "        \n",
    "        # Biological variables  \n",
    "        biological = [col for col in obs_columns if any(x in col.lower() for x in \n",
    "                     ['drug', 'cell_line', 'cell_type', 'tissue', 'treatment'])]\n",
    "        \n",
    "        print(f\"Potential confounders: {confounders}\")\n",
    "        print(f\"Biological variables: {biological}\")\n",
    "        \n",
    "        # Analyze variance explained by each\n",
    "        variance_analysis = {}\n",
    "        \n",
    "        for var_type, variables in [('Confounders', confounders), ('Biological', biological)]:\n",
    "            print(f\"\\n{var_type}:\")\n",
    "            for var in variables:\n",
    "                if var in self.adata.obs.columns:\n",
    "                    unique_vals = self.adata.obs[var].nunique()\n",
    "                    print(f\"  {var}: {unique_vals} unique values\")\n",
    "                    variance_analysis[var] = {\n",
    "                        'type': var_type,\n",
    "                        'unique_values': unique_vals\n",
    "                    }\n",
    "        \n",
    "        return variance_analysis\n",
    "    \n",
    "    def create_weight_umap(self, n_components=2):\n",
    "        \"\"\"\n",
    "        Create UMAP visualization of gene weights (genes as points)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            from umap import UMAP\n",
    "        except ImportError:\n",
    "            print(\"UMAP not available. Install with: pip install umap-learn\")\n",
    "            return None\n",
    "        \n",
    "        print(\"Creating UMAP of gene weight patterns...\")\n",
    "        \n",
    "        # Transpose weights so genes are rows, classes are features\n",
    "        weights_for_umap = self.weights.T  # Shape: (n_genes, n_classes)\n",
    "        \n",
    "        # Apply UMAP\n",
    "        umap_model = UMAP(n_components=n_components, random_state=42, n_neighbors=15, min_dist=0.1)\n",
    "        gene_embedding = umap_model.fit_transform(weights_for_umap)\n",
    "        \n",
    "        # Calculate gene importance for coloring\n",
    "        gene_importance = np.mean(np.abs(weights_for_umap), axis=1)\n",
    "        \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        scatter = plt.scatter(gene_embedding[:, 0], gene_embedding[:, 1], \n",
    "                            c=gene_importance, cmap='viridis', alpha=0.6, s=20)\n",
    "        plt.colorbar(scatter, label='Gene Importance')\n",
    "        plt.xlabel('UMAP 1')\n",
    "        plt.ylabel('UMAP 2')\n",
    "        plt.title('UMAP of Gene Weight Patterns')\n",
    "        \n",
    "        # Annotate top genes\n",
    "        top_gene_indices = np.argsort(gene_importance)[-20:]\n",
    "        for idx in top_gene_indices:\n",
    "            plt.annotate(self.gene_names[idx], \n",
    "                        (gene_embedding[idx, 0], gene_embedding[idx, 1]),\n",
    "                        xytext=(5, 5), textcoords='offset points',\n",
    "                        fontsize=8, alpha=0.7)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('umap_gene_weights.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        return gene_embedding\n",
    "    \n",
    "    def comprehensive_analysis(self):\n",
    "        \"\"\"\n",
    "        Run the complete analysis pipeline\n",
    "        \"\"\"\n",
    "        print(\"üöÄ Starting Comprehensive Linear Model Analysis\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # 1. Estimate uncertainty\n",
    "        print(\"\\nüìä Step 1: Estimating weight uncertainty...\")\n",
    "        uncertainty = self.bootstrap_uncertainty(n_bootstrap=50)\n",
    "        \n",
    "        # 2. Create volcano plots for top class comparisons\n",
    "        print(\"\\nüåã Step 2: Creating volcano plots...\")\n",
    "        # Compare first few classes\n",
    "        for i in range(min(3, len(self.class_names)-1)):\n",
    "            self.create_volcano_plot(i, i+1, uncertainty)\n",
    "        \n",
    "        # 3. Create dot plot\n",
    "        print(\"\\nüî¥ Step 3: Creating dot plot...\")\n",
    "        dot_data = self.create_dot_plot(top_k=15, uncertainty=uncertainty)\n",
    "        \n",
    "        # 4. Create heatmaps\n",
    "        print(\"\\nüî• Step 4: Creating heatmaps...\")\n",
    "        top_genes, class_corr = self.create_heatmap_analysis(top_k=25)\n",
    "        \n",
    "        # 5. Analyze confounders vs biology\n",
    "        print(\"\\nüß¨ Step 5: Analyzing confounders vs biology...\")\n",
    "        variance_analysis = self.analyze_confounders_vs_biology()\n",
    "        \n",
    "        # 6. Create UMAP\n",
    "        print(\"\\nüó∫Ô∏è  Step 6: Creating UMAP visualization...\")\n",
    "        gene_embedding = self.create_weight_umap()\n",
    "        \n",
    "        # 7. Summary statistics\n",
    "        print(\"\\nüìà Step 7: Summary statistics...\")\n",
    "        self._print_summary_stats(uncertainty, top_genes)\n",
    "        \n",
    "        print(\"\\n‚úÖ Analysis complete! Check the generated plots.\")\n",
    "        \n",
    "        return {\n",
    "            'uncertainty': uncertainty,\n",
    "            'dot_data': dot_data,\n",
    "            'top_genes': top_genes,\n",
    "            'class_correlations': class_corr,\n",
    "            'variance_analysis': variance_analysis,\n",
    "            'gene_embedding': gene_embedding\n",
    "        }\n",
    "    \n",
    "    def _print_summary_stats(self, uncertainty, top_genes):\n",
    "        \"\"\"Print summary statistics\"\"\"\n",
    "        weights_mean, weights_std = uncertainty\n",
    "        \n",
    "        print(f\"Model has {self.n_classes} classes and {self.n_genes} genes\")\n",
    "        print(f\"Average weight magnitude: {np.mean(np.abs(self.weights)):.4f}\")\n",
    "        print(f\"Average weight uncertainty: {np.mean(weights_std):.4f}\")\n",
    "        print(f\"Most variable class: {self.class_names[np.argmax(np.var(self.weights, axis=1))]}\")\n",
    "        print(f\"Most important gene: {self.gene_names[top_genes[0]]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4791ca-34ff-4578-bceb-9386f1ca2ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage\n",
    "def run_comprehensive_analysis(model, adata, datamodule=None):\n",
    "    \"\"\"\n",
    "    Main function to run all analyses\n",
    "    \"\"\"\n",
    "    analyzer = LinearModelAnalyzer(model, adata, datamodule)\n",
    "    results = analyzer.comprehensive_analysis()\n",
    "    return analyzer, results\n",
    "\n",
    "# Quick analysis function for immediate results\n",
    "def quick_analysis(model, adata, datamodule=None):\n",
    "    \"\"\"\n",
    "    Quick version focusing on key visualizations\n",
    "    \"\"\"\n",
    "    analyzer = LinearModelAnalyzer(model, adata, datamodule)\n",
    "    \n",
    "    print(\"üöÄ Quick Analysis Starting...\")\n",
    "    \n",
    "    # Simple uncertainty (fast)\n",
    "    uncertainty = analyzer._simple_weight_uncertainty()\n",
    "    \n",
    "    # Key visualizations\n",
    "    analyzer.create_volcano_plot(0, 1, (uncertainty[0], uncertainty[1]))\n",
    "    dot_data = analyzer.create_dot_plot(top_k=10, uncertainty=(uncertainty[0], uncertainty[1]))\n",
    "    top_genes, _ = analyzer.create_heatmap_analysis(top_k=20)\n",
    "    \n",
    "    print(\"‚úÖ Quick analysis complete!\")\n",
    "    \n",
    "    return analyzer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lamin_env",
   "language": "python",
   "name": "lamin_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
